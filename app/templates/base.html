<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>{{ title or "ALIS â€“ Paper Recommender" }}</title>
  <link href="https://cdn.jsdelivr.net/npm/bootswatch@5.3.3/dist/lux/bootstrap.min.css" rel="stylesheet">
  <link rel="icon" href="{{ url_for('static', filename='favicon.ico') }}">
</head>
<body>
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary mb-4">
    <div class="container">
      <a class="navbar-brand" href="/">
        <img src="{{ url_for('static', filename='ALIS-Logo.png') }}" alt="ALIS" height="30" style="background-color: white; padding: 3px; border-radius: 4px;" class="d-inline-block align-text-top">
        ALIS
      </a>
<button class="btn btn-outline-light ms-2" data-bs-toggle="modal" data-bs-target="#aboutModal">
  About
</button>

    </div>
  </nav>

  <div class="container py-5">
    {% block content %}{% endblock %}
  </div>

  <div class="modal fade" id="aboutModal" tabindex="-1" aria-labelledby="aboutModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-lg">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="aboutModalLabel">About</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <p><strong>ALIS</strong> (Algorithm-based Literature research In Science)</p>

        <h6>Data</h6>
        <ul>
            <li>Balanced subset of publications available on <a href="https://arxiv.org" target="_blank">arXiv</a> (~113k papers) </li>
            <li>Includes titles, abstracts, authors, categories and publication dates</li>
        </ul>
        
        <h6>Embeddings</h6>
        We used precomuted vector embeddings generated by the following models:
        <ul>
          <li><strong>MiniLM:</strong> 384-dimensional, lightweight semantic encoder <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank">[Doc]</a></li>
          <li><strong>SPECTER:</strong> 768-dimensional, trained on scientific papers + citation graphs <a href="https://github.com/allenai/specter" target="_blank">[GitHub]</a></li>
          <li><strong>SciBERT:</strong> 768-dimensional, trained on full-text scientific corpus with SciVocab <a href="https://huggingface.co/allenai/scibert_scivocab_uncased" target="_blank">[Doc]</a></li>
        </ul>

        <h6>How It Works</h6>
        <p>
          When you submit a query, the app:
          <ol>
            <li>Checks if your query matches an existing paper title exactly</li>
            <li>If found, uses that paper's embedding as an anchor for recommendations</li>
            <li>If not found, embeds your query string and compares it to all papers using cosine similarity</li>
          </ol>
        </p>

        <h6>Categories</h6>
        <p>
          Papers are categorized by <a href="https://arxiv.org/category_taxonomy" target="_blank">arXiv Category Taxonomy</a>.
        </p>

        <h6>References</h6>
        <ul>
          <li>MiniLM: Wang et al., <i>MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</i>, NeurIPS 2020 <a href="https://proceedings.neurips.cc/paper/2020/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">[PDF]</a></li>
          <li>SPECTER: Cohan et al., <i>SPECTER: Document-level Representation Learning using Citation-informed Transformers</i>, ACL 2020 <a href="https://aclanthology.org/2020.acl-main.207.pdf" target="_blank">[PDF]</a></li>
          <li>SciBERT: Beltagy et al., <i>SciBERT: A Pretrained Language Model for Scientific Text</i>, EMNLP 2019 <a href="https://aclanthology.org/D19-1371.pdf" target="_blank">[PDF]</a></li>
        </ul>

        <hr>
        <p class="text-muted small">
            <strong>Disclaimer:</strong> This tool is a prototype developed for academic research purposes. The recommendations provided are based on automated similarity computations and do not substitute for expert review.
        </p>
    </div>
    </div>
  </div>
</div>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>

{% block scripts %}{% endblock %}

{% block styles %}{% endblock %}

{% block extra %}{% endblock %}
